# DVC pipeline and experiment params

# data processing
data:
  extract:
    # num-segments: 10000000  # initial number of samples from wiki
    max-text-length: 220  # the maximum text length in characters
  generate:
    strategy: downsample  # strategy for class balancing the data
    min-word-count: 2
    test-size: 0.25  # data fraction to use for test
    compress: true

# current best model (used by default in scripts/evaluate_model.py)
model:
  name: WordRNNModel
  params:
    threshold: 0.5
  train:
    seed: 25512
    device: cuda
    # network arch
    num-layers: 2
    dropout: 0.1
    # number of steps
    batch-size: 128
    num-epochs: 50
    num-batches: 25
    num-eval-samples: 5000
    # lr and regularization
    learning-rate: 1e-2
    weight-decay: 1e-5
    # early stopping
    schedule-patience: 3
    schedule-factor: 0.5
    stopping-patience: 9
